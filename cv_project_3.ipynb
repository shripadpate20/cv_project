{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623c23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971437a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_video(input_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Could not open video file '{input_path}'\")\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    return cap, fps, frame_width, frame_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfdfefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_writer(output_path, fps, frame_width, frame_height):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    return cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc01161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bg_subtractor():\n",
    "    return cv2.createBackgroundSubtractorMOG2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fefd1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optical_flow(prev_frame, curr_frame):\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a2c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_motion_mask(flow, threshold=2.0):\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    return mag > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3b9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_draw_motion(curr_frame, flow, motion_mask, bg_subtractor):\n",
    "    fg_mask = bg_subtractor.apply(curr_frame)\n",
    "    fg_mask = cv2.bitwise_and(fg_mask, fg_mask, mask=motion_mask.astype(np.uint8) * 255)\n",
    "    \n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    result_frame = curr_frame.copy()\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 1000:  # Filter small contours\n",
    "            # Compute bounding box and centroid\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "            \n",
    "            # Compute average velocity within the bounding box\n",
    "            avg_velocity = np.mean(flow[y:y + h, x:x + w], axis=(0, 1))\n",
    "            velocity_magnitude = np.linalg.norm(avg_velocity)\n",
    "            \n",
    "            # Determine box color based on velocity magnitude\n",
    "            if velocity_magnitude > 5.0:\n",
    "                box_color = (0, 0, 255)  # Red (fast)\n",
    "            elif velocity_magnitude < 2.0:\n",
    "                box_color = (0, 255, 0)  # Green (slow)\n",
    "            else:\n",
    "                box_color = (0, 255, 255)  # Yellow (medium)\n",
    "            \n",
    "            # Draw bounding box and optical flow vector\n",
    "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), box_color, 2)\n",
    "            flow_start = (cx, cy)\n",
    "            flow_end = (int(cx + avg_velocity[0]), int(cy + avg_velocity[1]))\n",
    "            cv2.arrowedLine(result_frame, flow_start, flow_end, (255, 255, 0), 2)\n",
    "    \n",
    "    return result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0dc0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow_field(frame, flow, step=16):\n",
    "    h, w = frame.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    cv2.polylines(frame, lines, 0, (0, 255, 0), thickness=1, lineType=cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db6c7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_path, output_path):\n",
    "    try:\n",
    "        cap, fps, frame_width, frame_height = init_video(input_path)\n",
    "        out = create_video_writer(output_path, fps, frame_width, frame_height)\n",
    "        bg_subtractor = init_bg_subtractor()\n",
    "        \n",
    "        ret, prev_frame = cap.read()\n",
    "        if not ret:\n",
    "            raise IOError(\"Failed to read the first frame\")\n",
    "\n",
    "        while True:\n",
    "            ret, curr_frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            flow = compute_optical_flow(prev_frame, curr_frame)\n",
    "            motion_mask = compute_motion_mask(flow)\n",
    "            \n",
    "            result_frame = detect_and_draw_motion(curr_frame, flow, motion_mask, bg_subtractor)\n",
    "            draw_optical_flow_field(result_frame, flow, step=16)\n",
    "            \n",
    "            out.write(result_frame)\n",
    "            \n",
    "            prev_frame = curr_frame\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"Processed video saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during video processing: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5e740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved: proc_video1_version2.mp4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_video_path = 'sun17.mp4'\n",
    "    output_video_path = 'cv_project_3_1.mp4'\n",
    "    process_video(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4fe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
